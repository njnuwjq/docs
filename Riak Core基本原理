Riak Core基本原理 

Riak Core是一个分布式系统的开发框架，如果你的应用要采用分布式架构，凑巧你又选中了分布式哈希表这种分布式架构，则可以考虑使用Riak Core，不然自己从底层重新实现一个分布式哈希表实在是太麻烦了。 


1. 基于dynamo设计的Riak Core 


通过某种hash算法，对数据的某一特征计算哈希值，每份数据会对应着一个唯一的整数。这样处理后，这些数据将均匀的映射到一个整数区间上。 

对于Riak Core，它管理着一个整数范围为[0-2^160]整数空间，这个空间形成一个首尾相连的环。 

Riak Core把这个环平均划分成多个分区partition（默认是64个分区，当前的版本不能动态修改这个参数，据说将来会），partition在环上的Token作为此partition的唯一标识ID，每个partition交给一个或多个不同类型的vnode进程负责，每类vnode提供一套服务功能。partition的Token（或者说Index，Id）将作为对应vnode进程的id标识。如下图所示 
点击查看原始大小图片
（本图来自basho，版权属于basho。该图为了显示方便，整个环只被分成了32个分区） 

多个partition可以挤在一个物理节点上。但是怎么挤是有严格要求的，我觉得看懂这个图的关键在于：每一种颜色代表同一个物理节点；各个颜色按照固定的顺序循环。这保证了任意两个相邻的partition肯定不在同一个物理节点上。因此Dynamo Preference List上的节点不会是同一个物理节点，也即一份数据的多份副本不会在同一个物理节点上了。（这里一个物理节点指一个erlang虚拟机，而不是一个实际的计算机） 

Riak Core的基本原理是，通过一致性hash算法，系统要处理的数据（例如，KV要存储的业务数据，或者要处理的用户请求会话）会被riak_core随机的均匀分布在环上的各个分区中， 对每个数据的处理由该分区上的vnode进程负责。 

由于hash算法的特点，当我们要对某个数据集进行处理时，这个数据集会随机分布个不同的partition上，所以本质上是个数据并行的处理方式。 


dynamo的简单介绍可以看这里： 论文重读: Amazon Dynamoriak官方介绍在这里。 


2. Riak Core的设计：partition和vnode 

按照dynamo的设计思想，要处理的数据将会随机均匀的分布在dynamo ring上，Riak Core进一步将这些数据又以partition为基本单元组织起来。对数据的处理将以partition为单元，通过vnode进程进行处理。数据的处理（或者叫服务）又有很多种，每类服务对应着一类vnode进程。 

显然，partition是整个分布式系统并发、复制和容错的基本单元：以partition为单元进行数据并发处理；复制以partition为单元进行；容错也是如此：出错也以partition/vnode为单元出错。。。。 

对于基于Riak Core的分布式应用系统开发来说，vnode是最重要的概念，简单的说，每个vnode进程负责一份partition上数据的处理，数据处理逻辑由用户负责实现。 

一份partition可以有多个vnode进程管理，所以上图中a single partition/vnode应该是 a single partition with its assorted vnodes。 
（用riak_core_node_watcher:services()可以察看应用系统中有哪些vnode服务）。 

例子 写道
例如，对riak这个NoSQL数据库来说，最重要的服务是存储，在riak_kv_vnode模块中实现。模块实现了riak_core_vnode接口（实现了riak_core_vnode behaviour的回调函数）。 

此外riak还有两类重要的服务： 
riak的mapreduce基于riak_pipe实现，其vnode对应着riak_pipe_vnode模块。 
riak还提供了二级索引搜索（riak_search)服务，其vnode对应着riak_search_vnode模块。 

而一个实际的应用系统可能在功能上要比NoSQL数据库更多，它需要根据业务提供各种各样的服务，因此在vnode种类上就显得丰富多彩。比如rts实时日志统计这样一个例子就有两类vnode：riak_core_entry_vnode和riak_core_stat_vode，前者记录它负责的那份partition的所有数据，后者统计它负责的那份partition的所有数据。
